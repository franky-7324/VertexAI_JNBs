{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecfc60e4-a72a-4cfe-8d95-e437936e93e5",
   "metadata": {},
   "source": [
    "# Vertex AI SDK for Python: AutoML tabular training and prediction\n",
    "\n",
    "Inspired by : https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/automl/automl-tabular-classification.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0f4f06-f4a2-4cc0-bbff-e3aac9abdba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the packages\n",
    "! pip3 install --quiet --upgrade google-cloud-aiplatform \\\n",
    "                                 google-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc9631d-ddaf-4591-9a35-e94290115708",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python.exe -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46dee44-17e6-4d4e-9945-caa6929d0ba3",
   "metadata": {},
   "source": [
    "# Set Google Cloud project information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4093f8d-5636-4243-83bb-0821aa8eba76",
   "metadata": {},
   "source": [
    "# Create a Cloud Storage bucket\n",
    "\n",
    "Create a storage bucket to store intermediate artifacts such as datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67ae3df-2712-41ed-95de-11ce3d2cedf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "from google.cloud import storage\n",
    "import uuid # for generating unique bucket names\n",
    "\n",
    "# Path to your service account key file\n",
    "service_account_key_path = '<enter the path of the json key file of the Service Account>'\n",
    "\n",
    "# Initialize the client\n",
    "storage_client = storage.Client.from_service_account_json(service_account_key_path)\n",
    "\n",
    "# Declare variables\n",
    "PROJECT_ID = \"<enter your project ID>\"  # Replace with your GCP project ID\n",
    "unique_suffix = str(uuid.uuid4())[:8]  # Generate a unique suffix for the bucket name\n",
    "bucket_name = f\"{project_id}-bucket-{unique_suffix}\"  # Combine project ID and unique suffix\n",
    "LOCATION = \"asia-south1\"  # Mumbai region\n",
    "\n",
    "\n",
    "# Variable to hold the bucket URI\n",
    "BUCKET_URI = None\n",
    "\n",
    "# Function to create a bucket\n",
    "def create_bucket():\n",
    "    global BUCKET_URI\n",
    "    try:\n",
    "        # Create the bucket with a specific location\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        bucket.location = LOCATION\n",
    "        bucket = storage_client.create_bucket(bucket, project=PROJECT_ID)\n",
    "        print(f\"Bucket {bucket.name} created successfully in location {bucket.location}.\")\n",
    "        \n",
    "        # Assign the bucket URI\n",
    "        BUCKET_URI = f\"gs://{bucket.name}\"\n",
    "        print(f\"BUCKET_URI is set to: {BUCKET_URI}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Call the function to create the bucket\n",
    "create_bucket()\n",
    "\n",
    "print(BUCKET_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd64f05e-154a-4adf-8b31-5181edc9a941",
   "metadata": {},
   "source": [
    "# Copy dataset into your Cloud Storage bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d848a447-717f-4326-81b4-71c330ff963e",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPORT_FILE = \"petfinder-tabular-classification.csv\"\n",
    "! gsutil cp gs://cloud-samples-data/ai-platform-unified/datasets/tabular/{IMPORT_FILE} {BUCKET_URI}/data/\n",
    "\n",
    "gcs_source = f\"{BUCKET_URI}/data/{IMPORT_FILE}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1438242-509c-4811-be8c-90a5e11ed1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to list files in the bucket\n",
    "def list_files_in_bucket(bucket_name, prefix=None):\n",
    "    try:\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        blobs = storage_client.list_blobs(bucket_name, prefix=prefix)\n",
    "        print(f\"Files in bucket '{bucket_name}':\")\n",
    "        for blob in blobs:\n",
    "            print(f\"- {blob.name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "list_files_in_bucket(bucket_name, prefix=\"data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67326b0a-2ff3-4436-90f3-6b99674d099d",
   "metadata": {},
   "source": [
    "# Import Vertex AI SDK for Python\n",
    "\n",
    "Import Vertex AI SDK into python env and initialize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df60e736-a081-4e2d-8811-cd73f9b1c5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6258d70f-fea5-4c44-a828-b0d56807cd9e",
   "metadata": {},
   "source": [
    "# Tutorial "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6e696e-b83b-4f2a-9431-f521af3adf0d",
   "metadata": {},
   "source": [
    "## Create a Managed tabular dataset from a CSV\n",
    "\n",
    "This section creates a dataset from a CSV file stored on your GCS bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07ac46d-4ef7-4506-9170-7c5cbf0a0967",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = dataset = aiplatform.TabularDataset.create(\n",
    "    display_name=\"petfinder-tabular-dataset\",\n",
    "    gcs_source=gcs_source,\n",
    ")\n",
    "\n",
    "ds.resource_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a843ff-5f32-4f42-a3dc-3ba98b561bc5",
   "metadata": {},
   "source": [
    "## Launch a training job to create a model\n",
    "\n",
    "Once you've defined your training script, you'll create a model. The __run__ function creates a training pipeline that trains and creates a model object. After the training pipeline completes, the run function returns the model object.\n",
    "\n",
    "<span style=\"color:red\">Note: Running this step will take more than an hour to train the model.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751049e3-9eab-4cce-b35a-282a93e80e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = aiplatform.AutoMLTabularTrainingJob(\n",
    "    display_name=\"train-petfinder-automl-1\",\n",
    "    optimization_prediction_type=\"classification\",\n",
    "    column_transformations=[\n",
    "        {\"categorical\": {\"column_name\": \"Type\"}},\n",
    "        {\"numeric\": {\"column_name\": \"Age\"}},\n",
    "        {\"categorical\": {\"column_name\": \"Breed1\"}},\n",
    "        {\"categorical\": {\"column_name\": \"Color1\"}},\n",
    "        {\"categorical\": {\"column_name\": \"Color2\"}},\n",
    "        {\"categorical\": {\"column_name\": \"MaturitySize\"}},\n",
    "        {\"categorical\": {\"column_name\": \"FurLength\"}},\n",
    "        {\"categorical\": {\"column_name\": \"Vaccinated\"}},\n",
    "        {\"categorical\": {\"column_name\": \"Sterilized\"}},\n",
    "        {\"categorical\": {\"column_name\": \"Health\"}},\n",
    "        {\"numeric\": {\"column_name\": \"Fee\"}},\n",
    "        {\"numeric\": {\"column_name\": \"PhotoAmt\"}},\n",
    "    ],\n",
    ")\n",
    "\n",
    "# This takes about an hour to run\n",
    "model = job.run(\n",
    "    dataset=ds,\n",
    "    target_column=\"Adopted\",\n",
    "    training_fraction_split=0.8,\n",
    "    validation_fraction_split=0.1,\n",
    "    test_fraction_split=0.1,\n",
    "    model_display_name=\"adopted-prediction-model\",\n",
    "    disable_early_stopping=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfc7100-bba0-4354-b56f-5910134a54b3",
   "metadata": {},
   "source": [
    "## Deploy your model\n",
    "Before you use your model to make predictions, you need to deploy it to an endpoint. You can do this by calling the deploy function on the model resource. This function does two things:\n",
    "\n",
    "Creates an endpoint resource to which the model resource is deployed.\n",
    "Deploys the model resource to the endpoint resource.\n",
    "Deploy your model.\n",
    "\n",
    "NOTE: Wait until the model FINISHES deployment before proceeding to prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061a2292-8c29-40da-91e2-486d8960f0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = model.deploy(\n",
    "    machine_type=\"n1-standard-4\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae083ad3-23c9-4b00-a3ad-d13e64cb1281",
   "metadata": {},
   "source": [
    "## Predict on the endpoint\n",
    "This sample instance is taken from an observation in which Adopted = Yes\n",
    "Note that the values are all strings. Since the original data was in CSV format, everything is treated as a string. The transformations you defined when creating your AutoMLTabularTrainingJob inform Vertex AI to transform the inputs to their defined types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2535d7fa-8311-4d7e-b045-52d9ad7b26dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = endpoint.predict(\n",
    "    [\n",
    "        {\n",
    "            \"Type\": \"Cat\",\n",
    "            \"Age\": \"3\",\n",
    "            \"Breed1\": \"Tabby\",\n",
    "            \"Gender\": \"Male\",\n",
    "            \"Color1\": \"Black\",\n",
    "            \"Color2\": \"White\",\n",
    "            \"MaturitySize\": \"Small\",\n",
    "            \"FurLength\": \"Short\",\n",
    "            \"Vaccinated\": \"No\",\n",
    "            \"Sterilized\": \"No\",\n",
    "            \"Health\": \"Healthy\",\n",
    "            \"Fee\": \"100\",\n",
    "            \"PhotoAmt\": \"2\",\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b8b9e9",
   "metadata": {},
   "source": [
    "## Undeploy the model\n",
    "\n",
    "To undeploy your model resource from the serving endpoint resource, use the endpoint's undeploy method with the following parameter:\n",
    "\n",
    "deployed_model_id: The model deployment identifier returned by the prediction service when the model resource is deployed. You can retrieve the deployed_model_id using the prediction object's deployed_model_id property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a161592",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint.undeploy(deployed_model_id=prediction.deployed_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d29b89",
   "metadata": {},
   "source": [
    "Through the steps in this notebook, we were able to acheive the following tasks for Classification of tabular data:\n",
    "\n",
    "- Create a Vertex AI model training job.\n",
    "- Train an AutoML Tabular model.\n",
    "- Deploy the model resource to a serving endpoint resource.\n",
    "- Make a prediction by sending data.\n",
    "- Undeploy the model resource."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d628ac9",
   "metadata": {},
   "source": [
    "## Cleaning up\n",
    "To clean up all Google Cloud resources used in this project, you can delete the Google Cloud project you used for the tutorial.\n",
    "\n",
    "Otherwise, you can delete the individual resources you created in this tutorial:\n",
    "\n",
    "- Training Job\n",
    "- Model\n",
    "- Endpoint\n",
    "- Cloud Storage Bucket\n",
    "\n",
    "#### Note: You must delete any model resources deployed to the endpoint resource before deleting the endpoint resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b817ecbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: Setting this to true will delete everything in your bucket\n",
    "delete_bucket = False\n",
    "\n",
    "# Delete the training job\n",
    "job.delete()\n",
    "\n",
    "# Delete the model\n",
    "model.delete()\n",
    "\n",
    "# Delete the endpoint\n",
    "endpoint.delete()\n",
    "\n",
    "if delete_bucket:\n",
    "    ! gsutil -m rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
